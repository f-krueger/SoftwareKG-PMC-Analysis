{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import urllib\n",
    "from lxml import etree\n",
    "from rdflib.namespace import Namespace, XSD, RDF, RDFS\n",
    "from rdflib import Graph, plugin, URIRef, Literal\n",
    "from rdflib.serializer import Serializer\n",
    "import gzip\n",
    "import csv\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_path = \"/mnt/storage1/nlp/PMC_OA_PREPRO_LINKS\"\n",
    "pmc_path = \"/mnt/storage1/nlp/PMC_OA_XML/PMC_OA_XML_LINKS/\"\n",
    "\n",
    "# final graph URL\n",
    "base_url = \"http://data.gesis.org/softwarekg/PMC/\"\n",
    "\n",
    "context = {\n",
    "    \"schema\": Namespace(\"http://schema.org/\"),\n",
    "    \"sms\": Namespace(\"http://data.gesis.org/somesci/\"),\n",
    "    \"nif\" : Namespace(\"http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#\"),\n",
    "    \"wd\" : Namespace(\"http://www.wikidata.org/entity/\"),\n",
    "    \"xsd\": Namespace(\"http://www.w3.org/2001/XMLSchema#\"),\n",
    "    \"rdfs\": Namespace(\"http://www.w3.org/2000/01/rdf-schema#\"),\n",
    "    \"comment\": Namespace(\"http://www.w3.org/2000/01/rdf-schema#comment\"),\n",
    "    \"datacite\" : Namespace(\"http://purl.org/spar/datacite/\"),\n",
    "    \"rdf\" : Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"),\n",
    "    \"doi\" : Namespace(\"https://doi.org/\"),\n",
    "    \"skg\" : Namespace(\"http://data.gesis.org/softwarekg/PMC/\"),\n",
    "    \"skgv\" : Namespace(\"http://data.gesis.org/softwarekg/vocab/\"),\n",
    "    \"bibo\": Namespace(\"http://purl.org/ontology/bibo/\"),\n",
    "    \"skos\": Namespace(\"http://www.w3.org/2004/02/skos/core#\"),\n",
    "    \"dct\": Namespace(\"http://purl.org/dc/terms/\"),\n",
    "    \"dbpedia-owl\": Namespace(\"http://dbpedia.org/ontology/\"),\n",
    "    \"irao\": Namespace(\"http://ontology.ethereal.cz/\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load existing information\n",
    "\n",
    "The graph `common_g_out.jsonld` was generated from the publicly available information from the PubmedKG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "common_g = Graph()\n",
    "common_g.parse(\"common_g_out.jsonld\", format='json-ld')\n",
    "\n",
    "papers_with_journal = common_g.query(\"\"\"\n",
    "SELECT\n",
    "    ?paper \n",
    "    ?journal\n",
    "    ?journal_name\n",
    "    ?eissn\n",
    "    ?issn\n",
    "    ?publisher\n",
    "    ?publisher_name\n",
    "where{\n",
    "    ?paper <http://purl.org/dc/terms/isPartOf> ?journal.\n",
    "    ?journal <http://schema.org/name> ?journal_name.\n",
    "    OPTIONAL { ?journal <http://purl.org/ontology/bibo/eissn> ?eissn }\n",
    "    OPTIONAL { ?journal <http://purl.org/ontology/bibo/issn> ?issn }\n",
    "    OPTIONAL { ?journal <http://purl.org/dc/terms/publisher> ?publisher.\n",
    "                ?publisher <http://schema.org/name> ?publisher_name}\n",
    "}\"\"\")\n",
    "\n",
    "print(\"Papers with Journal: {}\".format(len(papers_with_journal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "common_papers = {}\n",
    "journal_by_issn = {}\n",
    "journal_by_eissn = {}\n",
    "journal_by_title = {}\n",
    "common_journals = []\n",
    "common_publishers = {}\n",
    "\n",
    "\n",
    "for row in tqdm.tqdm(papers_with_journal):\n",
    "    # just store all papers we already know, as we can ignore those information later on\n",
    "    paper_pmc_id = row[0].toPython().split('/')[-1][3:]\n",
    "    #print(paper_pmc_id)\n",
    "    common_papers[paper_pmc_id] = row[1].toPython()\n",
    "    \n",
    "    # in order to re-use the journals we should save the journal information\n",
    "    journal_id = row[1].toPython().split('/')[-1]\n",
    "    if journal_id not in common_journals:\n",
    "        common_journals.append(journal_id)\n",
    "        \n",
    "        journal = {\n",
    "            \"id\" : row[1],\n",
    "            \"name\" : row[2],\n",
    "            \"eissn\" : row[3],\n",
    "            \"issn\" : row[4]\n",
    "        }\n",
    "        journal_by_issn[str(journal['issn'])] = journal\n",
    "        journal_by_eissn[str(journal['eissn'])] = journal\n",
    "        lower_journal = journal['name'].lower().replace('&', 'and').lstrip().rstrip()\n",
    "        journal_by_title[journal['name'].lower().replace('&', 'and').lstrip().rstrip()] = journal\n",
    "    \n",
    "    if row[6]:\n",
    "        publisher_name = row[6].toPython()\n",
    "        if not publisher_name in common_publishers:\n",
    "            common_publishers[publisher_name] = row[5].toPython()\n",
    "    \n",
    "\n",
    "print(\"Number of Journals {}\".format(len(common_journals)))\n",
    "journal_count = len(common_journals)\n",
    "\n",
    "print(\"Number of Papers {}\".format(len(common_papers)))\n",
    "\n",
    "print(\"Number of publishers {}\".format(len(common_publishers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `PMX_ids.csv.gz` contains a mapping from *PMCID* to the Journal incl. some journal information just as title, issn, and eissn. The file was downloaded from  https://www.ncbi.nlm.nih.gov/pmc/pmctopmid/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pmc_info = {}\n",
    "\n",
    "with gzip.open(\"/mnt/storage1/nlp/PMC-ids.csv.gz\", 'rt') as a_in:\n",
    "    read = csv.reader(a_in, delimiter=',', quotechar='\"', escapechar='\\\\')\n",
    "    content = False\n",
    "    for row in tqdm.tqdm(read):\n",
    "        if content:\n",
    "            #print(row)\n",
    "            pmc_info[row[8][3:]] = {\n",
    "                'id' :row[8],\n",
    "                'title' : row[0],\n",
    "                'issn' : row[1].replace('-', '').strip(),\n",
    "                'eissn' : row[2].replace('-', '').strip(),\n",
    "                'doi' : row[7]\n",
    "            }\n",
    "        else:\n",
    "            content = True\n",
    "            print(row)\n",
    "        \n",
    "print(\"Read {} rows from journal mapping.\".format(len(pmc_info)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "Some URLs actually look weird, check them before usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from RDFlib\n",
    "#https://rdflib.readthedocs.io/en/stable/_modules/rdflib/term.html\n",
    "_invalid_uri_chars = '<>\" {}|\\\\^`'\n",
    "\n",
    "def _is_valid_uri(uri):\n",
    "    for c in _invalid_uri_chars:\n",
    "        if c in uri:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_from_file(fn): \n",
    "    entities = {}\n",
    "    with open(fn,'r') as f:\n",
    "        for line in f:\n",
    "            line_tokens = line.strip().split('\\t')\n",
    "\n",
    "            if line.startswith(\"T\"):\n",
    "                entity = {}\n",
    "                if \"SoftwareCoreference\" in line:\n",
    "                    #print(\"Skip Coreference in {}\".format(fn))\n",
    "                    continue\n",
    "                mention_tokens = line_tokens[1].split(' ')\n",
    "                entity['type'] = [e_type for e_type in mention_tokens[0].split('_')]\n",
    "                entity['mention'] = line_tokens[2]\n",
    "                e_len = int(mention_tokens[2]) - int(mention_tokens[1])\n",
    "                if len(entity['mention']) != e_len:\n",
    "                    print(\"Invalid entity length {} ({})\".format(e_len,len(entity['mention'])))\n",
    "                if len(line_tokens) == 4:\n",
    "                    # found disambiguation identifier\n",
    "                    entity['id'] = line_tokens[3]\n",
    "                entities[line_tokens[0]] = entity\n",
    "            elif line.startswith(\"R\"):\n",
    "                rel_tokens = line_tokens[1].split(' ')\n",
    "                if len(rel_tokens) != 3:\n",
    "                    print(\"Invalid relation {}\".format(line))\n",
    "                else:\n",
    "                    rel = rel_tokens[0].split('_')[0]\n",
    "                    arg_num1, e1 = rel_tokens[1].split(':')\n",
    "                    arg_num2, e2 = rel_tokens[2].split(':')\n",
    "                    if arg_num1 != 'Arg1' or arg_num2 != 'Arg2':\n",
    "                        print(\"Invalid relation arguments in {}\".format(line))\n",
    "                    if e2 in entities:\n",
    "                        entities[e2][rel] = e1\n",
    "            else:\n",
    "                print(\"Invalid line in {}:{}\".format(fn,line))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_from_article(fn):\n",
    "    general_info_paths = {\n",
    "        'journal' : \"//journal-meta//journal-title//text()\",\n",
    "        'title' : \"//title-group/article-title//text()\",\n",
    "        'pmc-id' : \"//article-meta/article-id[@pub-id-type='pmc']//text()\",\n",
    "        'publisher' : \"//publisher/publisher-name//text()\",\n",
    "    }\n",
    "\n",
    "    id_info_paths = { \n",
    "\n",
    "        'doi' : \"//article-meta/article-id[@pub-id-type='doi']\",\n",
    "        'pm-id' : \"//article-meta/article-id[@pub-id-type='pmid']\",\n",
    "        'issn' : \"//journal-meta/issn[@pub-type='ppub']\",\n",
    "        'eissn' : \"//journal-meta/issn[@pub-type='epub']\",\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    meta = {}\n",
    "    if not os.path.exists(fn):\n",
    "        print(\"Warning: Expected file {} missing.\".format(fn))\n",
    "        return None\n",
    "\n",
    "    with open(fn, 'r') as f:\n",
    "        tree = etree.parse(f)\n",
    "\n",
    "    # get general information\n",
    "    for k,p in general_info_paths.items():\n",
    "        tree_res = tree.xpath(p)\n",
    "        \n",
    "        if len(tree_res) < 1:\n",
    "            #print(\"Warning: Invalid number of results {} for node {} in document {}.\".format(len(tree_res), p, fn))\n",
    "            pass\n",
    "        else:\n",
    "            meta[k] = tree_res[0]\n",
    "\n",
    "    for k,p in id_info_paths.items():\n",
    "        tree_res = tree.xpath(p)\n",
    "        \n",
    "        if len(tree_res) > 0 and tree_res[0].text:\n",
    "            meta[k] = tree_res[0].text\n",
    "            meta[k] = urllib.parse.unquote(meta[k])\n",
    "            if k == 'doi' and not _is_valid_uri(meta[k]):\n",
    "                print(\"Warning: Found potentially problematic doi {} in {}\".format(meta[k], fn))\n",
    "\n",
    "    meta['keywords'] = [k.text for k in tree.xpath(\"//article-meta/kwd-group/kwd\")]\n",
    "    meta['type'] = [k for k in tree.xpath(\"//article/@article-type\")][0]\n",
    "\n",
    "    #get date\n",
    "    for att in ['epub', 'ppub','epub-ppub','pub']:\n",
    "        year = None\n",
    "        #TODO: current date XXXX-XX-XX -> invalid date is set to 1 \n",
    "        month = 1\n",
    "        day = 1\n",
    "        date_node = tree.xpath(\"//pub-date[@pub-type='{}']\".format(att))\n",
    "        if len(date_node) == 0:\n",
    "            date_node = tree.xpath(\"//pub-date[@date-type='{}']\".format(att))\n",
    "            if len(date_node) == 0:\n",
    "                continue\n",
    "        yn = date_node[0].xpath(\"year\")\n",
    "        mn = date_node[0].xpath(\"month\")\n",
    "        dn = date_node[0].xpath(\"day\")\n",
    "        \n",
    "        if len(yn) == 0:\n",
    "            continue\n",
    "        year = yn[0].text\n",
    "        \n",
    "        if len(mn) > 0:\n",
    "            month = mn[0].text\n",
    "        \n",
    "        if len(dn) > 0:\n",
    "            day = dn[0].text\n",
    "        \n",
    "        try:\n",
    "            meta['date'] = datetime.date(int(year), int(month), int(day)).isoformat()\n",
    "        except:\n",
    "            print(\"Warning: Invalid date: {}-{}-{} in document {}. (Resetting day to 1)\".format(year,month,day, fn))\n",
    "            meta['date'] = datetime.date(int(year), int(month), 1).isoformat()\n",
    "        break\n",
    "    if 'date' not in meta:\n",
    "        print(\"Warning: No publication date for document {}.\".format(fn))\n",
    "        \n",
    "    def add_node_text(dict,key,node, path):\n",
    "        res_node = node.xpath(path)\n",
    "        if len(res_node) >= 1:\n",
    "        #if len(res_node) == 1:\n",
    "            dict[key] = res_node[0].text\n",
    "        #elif len(res_node) > 1:\n",
    "        #    dict[key] =  [n.text for n in res_node]\n",
    "        return dict\n",
    "\n",
    "    def add_attrib(dict, key, node, path):\n",
    "        res_node = node.xpath(path)\n",
    "        if len(res_node) > 0:\n",
    "            dict[key] =  res_node\n",
    "        return dict\n",
    "\n",
    "    # get affiliation information\n",
    "    meta['affiliations'] = []\n",
    "    affiliations = tree.xpath(\"//article-meta/aff\")\n",
    "    for idx, aff_tree in enumerate(affiliations):\n",
    "        aff = {}\n",
    "        add_attrib(aff, 'id',aff_tree, \"@id\")\n",
    "        if not 'id' in aff:\n",
    "            aff['id'] = [idx]\n",
    "        #TODO: there is still some problem with the label/sub\n",
    "        add_attrib(aff,'name',aff_tree,\"string()\")\n",
    "        if not 'name' in aff:\n",
    "            # in some weired cases the affiliations are empty\n",
    "            aff['name'] = ''\n",
    "        aff['name'] = aff['name'].strip()\n",
    "       \n",
    "        #print(aff['name'])\n",
    "        for t in ['label','sup']:\n",
    "            label_node = aff_tree.xpath(t)\n",
    "            label_text = label_node[0].text if len(label_node) > 0 else '' \n",
    "            if not label_text:\n",
    "                continue\n",
    "            if not aff['name'].startswith(label_text):\n",
    "                pass\n",
    "                #print(\"Warning: {} does not start with {} in {}\".format(aff['name'], label_text, fn))\n",
    "            aff['name'] = aff['name'][len(label_text):] if aff['name'].startswith(label_text) else aff['name']\n",
    "        #print(aff['name'])\n",
    "        meta['affiliations'].append(aff)\n",
    "    #get author information\n",
    "    meta['authors'] = []\n",
    "    authors = tree.xpath(\"//contrib-group/contrib[@contrib-type='author']\")\n",
    "    for author_tree in authors:\n",
    "        author = {}\n",
    "        add_node_text(author, 'firstname', author_tree, \"name/given-names\")\n",
    "        add_node_text(author, 'lastname', author_tree,\"name/surname\")\n",
    "        add_node_text(author, 'email', author_tree, \"email\")\n",
    "        # TODO: Add corresponding author\n",
    "        add_node_text(author, 'orcid', author_tree,\"contrib-id[@contrib-id-type='orcid']\")\n",
    "        if 'orcid' in author:\n",
    "            #print(author['orcid'])\n",
    "            author['orcid'] = author['orcid'].strip()\n",
    "            if not _is_valid_uri(author['orcid']):\n",
    "                # ORCIDs must be valid URLs as the only consist of numbers, remove everything else\n",
    "                print(\"Warning: found potentially invalid orcid {} in {}\".format(author['orcid'], fn))\n",
    "                author.pop('orcid')\n",
    "        add_attrib(author, 'affiliation-id', author_tree, \"xref[@ref-type='aff']/@rid\")\n",
    "        add_attrib(author, 'corresponding', author_tree, \"@corresp\")\n",
    "\n",
    "        \n",
    "        meta['authors'].append(author)\n",
    "        #print(author)\n",
    "\n",
    "    # fix affilitation assigment\n",
    "    # Sometimes authors to not have an affilitation assigned\n",
    "    # We assign the affilition to them which is not assigned to any other author\n",
    "    author_affiliations = [a['affiliation-id'] for a in meta['authors'] if 'awas ffiliation-id' in a]\n",
    "    author_affiliations = [item for sublist in author_affiliations for item in sublist]\n",
    "    #print(author_affiliations)\n",
    "    affiliation_ids = [a['id'] for a in meta['affiliations'] if not a['id'] in author_affiliations]\n",
    "    affiliation_ids = [item for sublist in affiliation_ids for item in sublist]\n",
    "\n",
    "    #print(affiliation_ids)\n",
    "    for author in meta['authors']:\n",
    "        if 'affiliation-id' not in author:\n",
    "            #print(\"fix aff\")\n",
    "            # author has no affiliation yet, set list of un-assigned affiliations\n",
    "            author['affiliation-id'] = affiliation_ids\n",
    "            #print(author['affiliation-id'])\n",
    "\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issn_match = 0\n",
    "eissn_match = 0\n",
    "title_match = 0\n",
    "in_pmc = 0\n",
    "not_in_pmc=0\n",
    "\n",
    "\n",
    "def add_paperinfo_to_graph(g, f, infos):\n",
    "    global journal_count\n",
    "    global issn_match\n",
    "    global eissn_match\n",
    "    global title_match\n",
    "    global in_pmc\n",
    "    global not_in_pmc\n",
    "    \n",
    "    software_info = {}\n",
    "\n",
    "    \n",
    "    pmcfn = \".\".join(f.split(\".\")[:1]) + \".nxml\"\n",
    "    entities = entities_from_file(os.path.join(tag_path,f))\n",
    "    try:\n",
    "        meta = get_meta_from_article(os.path.join(pmc_path,pmcfn))\n",
    "    except Exception as e: \n",
    "        print(\"Warning: Cannot get meta data from {}\".format(pmcfn))\n",
    "        raise e\n",
    "    if not meta:\n",
    "        return\n",
    "    \n",
    "    software_info['article'] = meta['pmc-id']\n",
    "\n",
    "    article_id = \"skg:article/PMC{}\".format(meta['pmc-id'])\n",
    "    #print(article_id)\n",
    "    g.add((URIRef(article_id), RDF.type, URIRef(\"schema:ScholarlyArticle\")))\n",
    "    if 'title' in meta:\n",
    "        g.add((URIRef(article_id), URIRef(\"schema:name\"), Literal(meta['title'])))\n",
    "        software_info['title'] = meta['title']\n",
    "        \n",
    "    if 'type' in meta:\n",
    "        g.add((URIRef(article_id), URIRef(\"skgv:documentType\"), Literal(meta['type'])))\n",
    "        software_info['type'] = meta['type']\n",
    "        \n",
    "    if meta['pmc-id'] in pmc_info:\n",
    "        # we do have all information from the PMC mapping table and actually trust it more than the XML extraction\n",
    "        info = pmc_info[meta['pmc-id']]\n",
    "        in_pmc +=1\n",
    "    else: \n",
    "        not_in_pmc += 1\n",
    "        #print(meta)\n",
    "        #print(meta['pmc-id'])\n",
    "        info = {}\n",
    "        if 'doi' in meta:\n",
    "            info['doi'] = meta['doi']\n",
    "        if 'journal' in meta:\n",
    "            info['title'] = meta['journal']\n",
    "        if 'issn' in meta:            \n",
    "            info['issn'] = meta['issn'].replace('-','').strip()\n",
    "            #print(\"Found ISSN: {}\".format(info['issn']))\n",
    "        if 'eissn' in meta:\n",
    "            info['eissn'] = meta['eissn'].replace('-','').strip()\n",
    "            #print(\"Found EISSN: {}\".format(info['eissn']))\n",
    "    \n",
    "    # Add DOI either from PMC mapping or from XML\n",
    "    if 'doi' in info:\n",
    "        g.add((URIRef(article_id), URIRef(\"datacite:doi\"), URIRef(\"doi:{}\".format(info['doi']))))\n",
    "    #g.add((URIRef(article_id), URIRef(\"datacite:doi\"), URIRef(\"doi:{}\".format(meta['doi']))))\n",
    "\n",
    "    \n",
    "    # We now need to add information about the journal\n",
    "    # two possible cases arise here\n",
    "    # 1.) journal already available from common_g -> no action necessary\n",
    "    # 2.) not available -> take information from pmc mapping table\n",
    "\n",
    "    if meta['pmc-id'] not in common_papers:\n",
    "        # we do not have all information about the paper from common_g\n",
    "        # we have to add the information from either pmc_info or from XML\n",
    "        journal = None\n",
    "        if 'eissn' in info and info['eissn'] in journal_by_eissn:\n",
    "            eissn_match += 1\n",
    "            journal = journal_by_eissn[info['eissn']]\n",
    "        elif 'issn' in info and info['issn'] in journal_by_issn:\n",
    "            issn_match += 1\n",
    "            journal = journal_by_issn[info['issn']]\n",
    "        elif 'title' in info: \n",
    "            lower_title = info['title'].lower().replace('&', 'and').lstrip().rstrip()\n",
    "            if lower_title in journal_by_title:\n",
    "                title_match += 1\n",
    "                journal = journal_by_title[lower_title]\n",
    "        \n",
    "        if not journal:\n",
    "            journal = {}\n",
    "            #print(journal_count)\n",
    "            journal['id'] = journal_count\n",
    "            journal['title'] = info['title']\n",
    "            if 'issn' in info:\n",
    "                journal_by_issn[info['issn']] = journal\n",
    "            if 'eissn' in info:\n",
    "                journal_by_eissn[info['eissn']] = journal\n",
    "\n",
    "            journal_count += 1\n",
    "            journal_by_title[info['title'].lower().replace('&', 'and').lstrip().rstrip()] = journal #.lower().replace('&', 'and').lstrip().rstrip()\n",
    "            journal_uri = URIRef(\"skg:journal/{}\".format(journal['id']))\n",
    "            g.add((journal_uri, URIRef(\"schema:name\"), Literal(journal['title'])))\n",
    "            g.add((journal_uri, RDF.type, URIRef(\"bibo:Journal\")))\n",
    "        else:\n",
    "            journal_uri = URIRef(\"skg:journal/{}\".format(journal['id']))\n",
    "\n",
    "        g.add((URIRef(article_id), URIRef(\"dct:isPartOf\"), journal_uri))\n",
    "        software_info['journal'] = journal_uri\n",
    "\n",
    "        # we need the publisher now\n",
    "        \n",
    "        \n",
    "        if 'publisher' in meta:\n",
    "            if meta['publisher'] in common_publishers:\n",
    "                publisher_uri = URIRef(common_publishers[meta['publisher']])\n",
    "            else:\n",
    "                publisher_url = \"skg:publisher/{}\".format(len(common_publishers))\n",
    "                publisher_uri = URIRef(publisher_url)\n",
    "                g.add((publisher_uri, RDF.type, URIRef(\"schema:Organization\")))\n",
    "                g.add((publisher_uri, URIRef(\"schema:name\"), Literal(meta['publisher'])))\n",
    "                common_publishers[meta['publisher']] = publisher_url\n",
    "            g.add((journal_uri, URIRef(\"dct:publisher\"), publisher_uri))\n",
    "    else:\n",
    "        software_info['journal'] = common_papers[meta['pmc-id']]\n",
    "\n",
    "        \n",
    "    if 'keywords' in meta:\n",
    "        for k in meta['keywords']:\n",
    "            g.add((URIRef(article_id), URIRef(\"schema:keywords\"), Literal(k)))\n",
    "    if 'date' in meta:\n",
    "        g.add((URIRef(article_id), URIRef(\"schema:datePublished\"), Literal(meta['date'], datatype= XSD.date)))\n",
    "        software_info['date'] = meta['date']\n",
    "    affs = {}\n",
    "    if 'affiliations' in meta:\n",
    "        for idx, a in enumerate(meta['affiliations']):\n",
    "            aff_id = \"{}/affilation/A{}\".format(article_id,idx)\n",
    "            if 'id' not in a:\n",
    "                \n",
    "                if len(meta['affiliations']) == 1:\n",
    "                    affs['dummy'] = aff_id\n",
    "                else:\n",
    "                    print(\"Warning: Affiliation ID for {} missing in {} but multiple affiliations given\".format(a,pmcfn))\n",
    "                    return\n",
    "            else:\n",
    "                # TODO: Why list [0]?\n",
    "                affs[a['id'][0]] = aff_id\n",
    "            g.add((URIRef(aff_id), RDF.type, URIRef(\"schema:Organization\")))\n",
    "            g.add((URIRef(aff_id), URIRef(\"schema:name\"), Literal(a['name'])))\n",
    "    if 'authors' in meta:\n",
    "        for idx, author in enumerate(meta['authors']):\n",
    "            author_id = \"{}/author/A{}\".format(article_id,idx)\n",
    "            g.add((URIRef(article_id), URIRef(\"schema:author\"), URIRef(author_id)))\n",
    "            g.add((URIRef(author_id), RDF.type, URIRef(\"schema:Person\")))\n",
    "            if 'firstname' in author:\n",
    "                g.add((URIRef(author_id), URIRef(\"schema:givenName\"), Literal(author['firstname'])))\n",
    "            if 'lastname' in author:\n",
    "                g.add((URIRef(author_id), URIRef(\"schema:familyName\"), Literal(author['lastname'])))\n",
    "            if 'orcid' in author:\n",
    "                g.add((URIRef(author_id), URIRef(\"dbpedia-owl:orcidId\"), URIRef(author['orcid'])))\n",
    "            if 'affiliation-id' in author:\n",
    "                for author_aff in author['affiliation-id']:\n",
    "                    #print(author_aff)\n",
    "                    #print(affs)\n",
    "                    if author_aff in affs:\n",
    "                        g.add((URIRef(author_id), URIRef(\"schema:affiliation\"), URIRef(affs[author_aff])))\n",
    "            elif len(affs) == 1 and 'dummy' in affs: # no affiliation id given at all, assume that the only one belongs to each author\n",
    "                g.add((URIRef(author_id), URIRef(\"schema:affiliation\"), URIRef(affs['dummy'])))\n",
    "    # create entities\n",
    "    #print(entities)\n",
    "    software_info['mentions'] = []\n",
    "    for eid, entity in entities.items():\n",
    "        software_id = None\n",
    "        mention_info = {}\n",
    "        #print(entity)   \n",
    "        mention_id = \"{}/mentions/{}\".format(article_id,eid)\n",
    "        g.add((URIRef(article_id), URIRef(\"schema:mentions\"), URIRef(mention_id)))\n",
    "        g.add((URIRef(mention_id), RDF.type, URIRef(\"nif:String\")))\n",
    "        #mention_info['id'] = mention_id\n",
    "        \n",
    "        if 'id' in entity:\n",
    "            software_id = \"skg:software/{}\".format(entity['id'])\n",
    "            g.add((URIRef(mention_id), URIRef(\"skgv:software\"), URIRef(software_id)))\n",
    "            g.add((URIRef(software_id), RDF.type, URIRef(\"irao:Software\")))\n",
    "            software_info['mentions'].append(entity['id'])\n",
    "        \n",
    "        for key, value in entity.items():\n",
    "            if key == 'mention':\n",
    "                g.add((URIRef(mention_id), URIRef(\"nif:isString\"), Literal(value)))\n",
    "            elif key == 'id':\n",
    "                continue\n",
    "            elif key == 'type':\n",
    "                for t in entity['type']:\n",
    "                    if t in ['Unknown']:\n",
    "                        # Unknown -> we were not able to determine the type for sure\n",
    "                        pass \n",
    "                    elif t in ['Creation', 'Usage', 'Deposition', 'Mention']:\n",
    "                        m = {\n",
    "                            'Creation':'skgv:MentionType_Creation',\n",
    "                            'Usage' : 'skgv:MentionType_Usage',\n",
    "                            'Deposition' : 'skgv:MentionType_Deposition',\n",
    "                            'Mention' : 'skgv:MentionType_Allusion'\n",
    "                        }\n",
    "                        g.add((URIRef(mention_id), URIRef(\"skgv:mentionType\"),URIRef(m[t])))\n",
    "                        #mention_info['mentiontype'] = m[t]\n",
    "                    elif t in ['ProgrammingEnvironment','Application','OperatingSystem','PlugIn']:\n",
    "                        g.add((URIRef(mention_id), URIRef(\"skgv:softwareType\"),URIRef(\"skgv:{}\".format(t))))\n",
    "                        #mention_info['softwaretype'] = t\n",
    "                    elif t in ['Version', 'Developer', 'URL', 'Citation', 'Extension', 'Release', 'Abbreviation', \n",
    "                               'Fullname', 'License','AlternativeName']:\n",
    "                        g.add((URIRef(mention_id), URIRef(\"skgv:informationType\"),URIRef(\"skgv:{}\".format(t))))\n",
    "                        #mention_info['infotype'] = t\n",
    "                    else:\n",
    "                        raise Exception('Unknown mention type: {}'.format(t))\n",
    "            else:\n",
    "                #print(\"{}:{}\".format(key,value))\n",
    "                g.add((URIRef(mention_id), URIRef(\"skgv:referredToBy{}\".format(key)), URIRef(\"{}/mentions/{}\".format(article_id, value))))\n",
    "            if 'software' in mention_info:\n",
    "                # we only add software specific rows\n",
    "                software_info['mentions'].append(mention_info)\n",
    "#        if 'id' in entity:\n",
    "#            g.add((URIRef(mention_id), URIRef(\"skg:software\"), ))\n",
    "    infos.append(software_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "g = Graph()\n",
    "\n",
    "list_of_files = [fn for fn in os.listdir(tag_path) if fn.startswith(\"PMC\") and fn.endswith(\".ann.unique\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def gen_n_papers(start, n, files):\n",
    "    publisher_list = []\n",
    "    softwareid_list = []\n",
    "    data_list = []\n",
    "    g = Graph()\n",
    "    infos = []\n",
    "    n = min(n,len(files))\n",
    "    start = max(start,0)\n",
    "    \n",
    "    for f in tqdm.tqdm(files[start:n]):\n",
    "        add_paperinfo_to_graph(g, f, data_list)\n",
    "\n",
    "    g.serialize(format=\"json-ld\", context=context, destination=\"softwarekg_{}-{}.jsonld\".format(start,n))\n",
    "    \n",
    "    ll = [pd.DataFrame(article).drop_duplicates() for article in data_list]\n",
    "    pd.concat(ll).to_csv('software_in_articles_{}-{}.csv'.format(start,n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n = 50\n",
    "step = int(len(list_of_files)/n)\n",
    "\n",
    "i = 0\n",
    "while i < len(list_of_files):\n",
    "    gen_n_papers(i, i+step, list_of_files)\n",
    "    i += step + 1\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "230cf635071c9808c0220ccb44c4f562135dfd3e8a1a5bab0362ea9c7f8ff142"
  },
  "kernelspec": {
   "display_name": "Johnson_NLP",
   "language": "python",
   "name": "johnson_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
